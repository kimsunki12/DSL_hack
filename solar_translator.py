import os
from fastapi import FastAPI
from pydantic import BaseModel
from langchain.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langserve import add_routes
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ (í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ì„ ê²½ìš° ëŒ€ë¹„)
load_dotenv()

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI()

# UPSTAGE_API_KEY ê°€ì ¸ì˜¤ê¸° (Solar LLM API í‚¤)
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise ValueError("ğŸš¨ í™˜ê²½ ë³€ìˆ˜ 'UPSTAGE_API_KEY'ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")

# Solar LLM ëª¨ë¸ ì„¤ì • (API í‚¤ ì ìš©)
solar_llm = ChatOpenAI(model="gpt-4o", temperature=0.7, openai_api_key=api_key)

# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •
prompt = ChatPromptTemplate.from_template("Translate the following text to {target_language}: {text}")

# LangChain ì²´ì¸ ì„¤ì •
chain = prompt | solar_llm

# LangChain ì²´ì¸ì„ FastAPI ì—”ë“œí¬ì¸íŠ¸ë¡œ ì¶”ê°€
add_routes(app, chain, path="/translate")

# API ìš”ì²­ ëª¨ë¸ ì •ì˜
class TranslationRequest(BaseModel):
    text: str
    target_language: str

# ë²ˆì—­ API ì—”ë“œí¬ì¸íŠ¸
@app.post("/translate")
async def translate_text(request: TranslationRequest):
    """ì‚¬ìš©ìê°€ ì…ë ¥í•œ í…ìŠ¤íŠ¸ë¥¼ ì›í•˜ëŠ” ì–¸ì–´ë¡œ ë²ˆì—­"""
    result = await chain.ainvoke({"text": request.text, "target_language": request.target_language})
    return {"translated_text": str(result)}

# FastAPI ì„œë²„ ì‹¤í–‰
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="localhost", port=8000)
